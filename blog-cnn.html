<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-0ZF5XJEMRZ"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-0ZF5XJEMRZ');
</script>
    <meta name="viewport" content="width=device-width, initial-scale=1.0, shrink-to-fit=no">
    <title>TUM.ai - Blog - CNNs in Keras</title>
    <meta property="og:type" content="website">
    <meta property="og:image" content="https://tum-ai.com/assets/img/logo/logo_final_black_correctshape.png">
    <meta name="description" content="This article wants to explain the functionality of the different layers in convolutional neural networks and show a simple CNN implementation in the commonly used python machine learning framework keras.">
    <link rel="icon" type="image/png" sizes="800x800" href="assets/img/logo/Group%2014logo_small.png">
    <link rel="icon" type="image/png" sizes="800x800" href="assets/img/logo/Group%2014logo_small.png">
    <link rel="icon" type="image/png" sizes="800x800" href="assets/img/logo/Group%2014logo_small.png">
    <link rel="icon" type="image/png" sizes="800x800" href="assets/img/logo/Group%2014logo_small.png">
    <link rel="icon" type="image/png" sizes="800x800" href="assets/img/logo/Group%2014logo_small.png">
    <link rel="stylesheet" href="assets/bootstrap/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato:300,400,700,300italic,400italic,700italic">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Bitter:400,700">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lora">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Montserrat">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:100,300,400,500,700">
    <link rel="stylesheet" href="assets/fonts/fontawesome-all.min.css">
    <link rel="stylesheet" href="assets/fonts/font-awesome.min.css">
    <link rel="stylesheet" href="assets/fonts/ionicons.min.css">
    <link rel="stylesheet" href="assets/fonts/line-awesome.min.css">
    <link rel="stylesheet" href="assets/fonts/fontawesome5-overrides.min.css">
    <link rel="stylesheet" href="assets/css/-Countdown-BS4-.css">
    <link rel="stylesheet" href="assets/css/aboutus.css">
    <link rel="stylesheet" href="assets/css/accordeon.css">
    <link rel="stylesheet" href="assets/css/Animated-Typing-With-Blinking.css">
    <link rel="stylesheet" href="assets/css/Article-Clean.css">
    <link rel="stylesheet" href="assets/css/Article-List.css">
    <link rel="stylesheet" href="assets/css/Beautiful-Warning-Note--Callout.css">
    <link rel="stylesheet" href="assets/css/blogEntryOverview.css">
    <link rel="stylesheet" href="assets/css/Bold-BS4-Cards-with-Hover-Effect-74-1.css">
    <link rel="stylesheet" href="assets/css/Bold-BS4-Cards-with-Hover-Effect-74.css">
    <link rel="stylesheet" href="assets/css/Bold-BS4-Image-Caption-Hover-Effect-3.css">
    <link rel="stylesheet" href="assets/css/Bold-BS4-Jumbotron-with-Particles-js-1.css">
    <link rel="stylesheet" href="assets/css/Bold-BS4-Jumbotron-with-Particles-js-2.css">
    <link rel="stylesheet" href="assets/css/Bold-BS4-Jumbotron-with-Particles-js.css">
    <link rel="stylesheet" href="assets/css/Brands.css">
    <link rel="stylesheet" href="assets/css/card-3-column-animation-shadows-images.css">
    <link rel="stylesheet" href="assets/css/Card-Carousel-1.css">
    <link rel="stylesheet" href="assets/css/Card-Carousel.css">
    <link rel="stylesheet" href="assets/css/Card-Group1-Shadow.css">
    <link rel="stylesheet" href="assets/css/caroussel_linkedin.css">
    <link rel="stylesheet" href="assets/css/Clients.css">
    <link rel="stylesheet" href="assets/css/Contact-Form-Clean-1.css">
    <link rel="stylesheet" href="assets/css/Contact-Form-Clean.css">
    <link rel="stylesheet" href="assets/css/Cookie-Banner-1.css">
    <link rel="stylesheet" href="assets/css/Cookie-Banner.css">
    <link rel="stylesheet" href="assets/css/custom.css">
    <link rel="stylesheet" href="assets/css/dh-card-image-left-dark.css">
    <link rel="stylesheet" href="assets/css/eventBox.css">
    <link rel="stylesheet" href="assets/css/Features-Boxed.css">
    <link rel="stylesheet" href="assets/css/Features-Clean.css">
    <link rel="stylesheet" href="assets/css/flipCart.css">
    <link rel="stylesheet" href="assets/css/flowchart.css">
    <link rel="stylesheet" href="assets/css/Footer-Basic.css">
    <link rel="stylesheet" href="assets/css/Footer-Dark.css">
    <link rel="stylesheet" href="assets/css/forPartners.css">
    <link rel="stylesheet" href="assets/css/forStudents.css">
    <link rel="stylesheet" href="assets/css/Header-Dark.css">
    <link rel="stylesheet" href="assets/css/Highlight-Blue.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.5.2/animate.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/aos/2.3.4/aos.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Swiper/3.3.1/css/swiper.min.css">
    <link rel="stylesheet" href="https://pretix.eu/tumai/makeathon-oct21/widget/v1.css">
    <link rel="stylesheet" href="https://pretix.eu/tumai/makeathon/widget/v1.css">
    <link rel="stylesheet" href="https://www.w3schools.com/w3css/4/w3.css">
    <link rel="stylesheet" href="assets/css/Image-Hover-Effect.css">
    <link rel="stylesheet" href="assets/css/joinslackspace.css">
    <link rel="stylesheet" href="assets/css/ladingpage.css">
    <link rel="stylesheet" href="assets/css/Latest-Blog.css">
    <link rel="stylesheet" href="assets/css/Map-Clean.css">
    <link rel="stylesheet" href="assets/css/menu-collapse-ultimate-1.css">
    <link rel="stylesheet" href="assets/css/menu-collapse-ultimate.css">
    <link rel="stylesheet" href="assets/css/Navigation-Clean.css">
    <link rel="stylesheet" href="assets/css/Navigation-with-Button.css">
    <link rel="stylesheet" href="assets/css/Navigation-with-Search.css">
    <link rel="stylesheet" href="assets/css/parallaxStars.css">
    <link rel="stylesheet" href="assets/css/Popup-Modal-with-Cookie.css">
    <link rel="stylesheet" href="assets/css/Pretty-Registration-Form.css">
    <link rel="stylesheet" href="assets/css/Process-Steps.css">
    <link rel="stylesheet" href="assets/css/Registration-Form-with-Photo.css">
    <link rel="stylesheet" href="assets/css/registrationForm.css">
    <link rel="stylesheet" href="assets/css/responsive-blog-card-slider.css">
    <link rel="stylesheet" href="assets/css/Responsive-Blog-Library.css">
    <link rel="stylesheet" href="assets/css/Responsive-Full-Width-Grid-from-codedrops.css">
    <link rel="stylesheet" href="assets/css/Responsive-Youtube-Embed.css">
    <link rel="stylesheet" href="assets/css/Simple-Slider.css">
    <link rel="stylesheet" href="assets/css/slider_mainpage.css">
    <link rel="stylesheet" href="assets/css/tabSlider.css">
    <link rel="stylesheet" href="assets/css/Team-Boxed.css">
    <link rel="stylesheet" href="assets/css/Team-Grid.css">
    <link rel="stylesheet" href="assets/css/Team.css">
    <link rel="stylesheet" href="assets/css/Testimonials.css">
    <link rel="stylesheet" href="assets/css/timeline-1.css">
    <link rel="stylesheet" href="assets/css/Timeline-F19687.css">
    <link rel="stylesheet" href="assets/css/Timeline.css">
    <link rel="stylesheet" href="assets/css/title_font.css">
    <link rel="stylesheet" href="assets/css/Toggle-Switch.css">
    <link rel="stylesheet" href="assets/css/untitled.css">
    <link rel="stylesheet" href="assets/css/Video-Parallax-Background.css">
    <link rel="stylesheet" href="assets/css/video.css">
</head>

<body>
    <nav class="navbar navbar-light navbar-expand-lg shadow navigation-clean-button sticky-top" style="font-family: Lato, sans-serif;opacity: 1;height: 65px;padding-top: 0px;padding-left: 12px;padding-bottom: 0px;background: rgb(11,11,11);filter: blur(0px);">
        <div class="container" style="background-color: transparent;"><a class="navbar-brand" style="padding: 0px;height: 65px;width: 160px;" href="/"><img data-bss-disabled-mobile="true" data-aos="zoom-out-down" data-aos-offset="0" data-aos-delay="50" data-aos-once="true" src="assets/img/logo/logo_final_white_correctshape.png" style="max-height: 100%;padding: 13px;margin-right: 0px;width: auto;height: 90%;padding-left: 7px;padding-right: 0px;padding-top: 12px;padding-bottom: 12px;margin-top: 2px;margin-left: 0px;"></a><button data-toggle="collapse" class="navbar-toggler" data-target="#navcol-1"><span class="sr-only">Toggle navigation</span><span class="navbar-toggler-icon" style="color: rgb(255,254,254);filter: brightness(200%) contrast(200%) invert(100%);margin-bottom: 1px;"></span></button>
            <div class="collapse navbar-collapse text-center" id="navcol-1" style="opacity: 1;width: 109%;background: rgba(11,11,11,0.99);border-radius: 10px;">
                <ul class="navbar-nav ml-auto" style="color: #fcfeff;">
                    <li class="nav-item"></li>
                    <li class="nav-item"></li>
                    <li class="nav-item"><a class="nav-link" href="projects" style="color: #ffffff;font-family: Lato, sans-serif;padding: 12px 12px;font-size: 18px;">Projects</a></li>
                    <li class="nav-item"><a class="nav-link" href="forStudents" style="color: #ffffff;font-family: Lato, sans-serif;padding: 12px 12px;font-size: 18px;">For Students</a></li>
                    <li class="nav-item"><a class="nav-link" href="forPartners" style="color: #ffffff;font-family: Lato, sans-serif;padding: 12px 12px;font-size: 18px;">For Partners</a></li>
                    <li class="nav-item"><a class="nav-link" href="aboutus" style="color: #ffffff;font-family: Lato, sans-serif;padding: 12px 12px;font-size: 18px;">Team Members</a></li>
                    <li class="nav-item"><a class="nav-link" href="blog" style="color: #ffffff;font-family: Lato, sans-serif;padding: 12px;font-size: 18px;font-weight: bold;">Blog</a></li>
                </ul><a class="btn" role="button" data-bss-hover-animate="pulse" href="https://www.linkedin.com/company/tum-ai/" style="margin: 5px 5px;font-family: Lato, sans-serif;font-size: 5px;background: url(&quot;assets/img/linkedin_round_white.png&quot;) right / cover no-repeat, rgb(255,255,255);margin-left: 0px;margin-bottom: 10px;margin-top: 10px;padding-left: 0.25px;padding-right: 13.25px;border-radius: 21px;margin-right: 1px;width: 37.25px;height: 36.25px;padding-top: 4.625px;filter: brightness(99%) contrast(101%) grayscale(96%) invert(100%) saturate(119%);transform: scale(1);border-width: 2px;border-color: #ffffff;"></a><a class="btn" role="button" data-bss-hover-animate="pulse" style="margin: 5px 5px;font-family: Lato, sans-serif;font-size: 0px;background: url(&quot;assets/img/other/Instagram_logo.png&quot;) center / cover no-repeat, rgba(111,66,193,0);margin-left: 1px;margin-bottom: 10px;margin-top: 10px;padding-left: 12.25px;padding-right: 13.25px;border-radius: 19px;margin-right: 13px;width: 36.25px;height: 36.25px;padding-top: 4.625px;filter: brightness(108%) contrast(200%) grayscale(100%) invert(0%) saturate(200%);color: rgb(255,255,255);border-width: 5px;border-color: rgb(42,42,42);" href="https://www.instagram.com/tum.ai_official/?hl=de"></a><a class="btn" role="button" data-bss-hover-animate="pulse" href="https://join.slack.com/t/tumaipublic/shared_invite/zt-10kg0t1f9-JLRXDxY_d_vprKWgab0cVw" style="margin: 5px 5px;font-family: Lato, sans-serif;font-size: 5px;background: url(&quot;assets/img/slack_black_logo_icon_147081.png&quot;) center / cover no-repeat, rgba(111,66,193,0);margin-left: -10px;margin-bottom: 10px;margin-top: 10px;padding-left: 12.25px;padding-right: 13.25px;border-radius: 18px;margin-right: 9px;width: 37.25px;height: 36.25px;padding-top: 4.625px;filter: grayscale(100%) invert(100%);border-width: 2px;border-color: rgb(0,0,0);"></a><button class="btn btn-primary" data-bss-hover-animate="pulse" data-toggle="modal" data-target="#modal1" type="button" style="margin: 5px 5px;font-family: Lato, sans-serif;font-size: 18px;background: linear-gradient(30deg, var(--indigo) 0%, #45b69c 100%), var(--purple);margin-left: 0px;border-width: 0px;border-color: rgb(255,255,255);margin-bottom: 10px;margin-top: 10px;padding-left: 12.25px;padding-right: 13.25px;border-radius: 49px;margin-right: 12px;width: 93.8125px;height: 36.25px;padding-top: 4.625px;">Contact</button>
            </div>
        </div>
    </nav>
    <div class="modal fade" role="dialog" tabindex="-1" id="modal1">
        <div class="modal-dialog modal-lg" role="document">
            <div class="modal-content">
                <div class="modal-header" style="padding-top: 16px;padding-bottom: 14px;">
                    <h1 class="modal-title" style="padding-left: 15px;"><strong>Let's connect!</strong></h1><button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
                </div>
                <div class="modal-body" style="padding-right: 15px;padding-bottom: 5px;margin-right: 20px;margin-left: 20px;margin-top: 20px;margin-bottom: 99px;padding-top: 7px;">
                    <div class="row">
                        <div class="col" style="padding-right: 0px;padding-left: 0px;margin-right: 15px;margin-left: 15px;margin-bottom: -47px;">
                            <div class="mx-auto testimonial-item mb-5 mb-lg-0"><img class="img-fluid mb-3" src="assets/img/logo/logo_final_black_correctshape.png" style="padding-left: 0px;padding-right: 0px;border-radius: 10px;">
                                <h5 style="padding-right: 0px;padding-left: 15px;margin-right: 0px;margin-bottom: 0px;"><strong>Just reach out to us!</strong><br><br></h5>
                                <p class="text-left font-weight-light mb-0" style="padding-right: 0px;padding-left: 15px;padding-bottom: 43px;color: rgb(0,0,0);">TUM.ai Operations Team<br>Arcisstraße 21.<br>80333 München<br>contact@tum-ai.com<br></p>
                            </div>
                        </div>
                        <div class="col" style="padding-right: 0px;padding-left: 0px;">
                            <div class="container" style="padding-right: 0px;padding-left: 0px;width: 100%;">
                                <section class="contact-clean" style="padding-top: 0px;padding-bottom: 0px;background: rgb(239,237,237);border-radius: 10px;margin-right: 15px;margin-left: 15px;"></section>
                            </div><a class="btn btn-primary" role="button" data-bss-hover-animate="pulse" style="margin: 5px 5px;font-family: Lato, sans-serif;font-size: 18px;background: linear-gradient(30deg, var(--indigo) 0%, #45b69c 100%), var(--purple);margin-left: 26px;border-width: 0px;border-color: rgb(255,255,255);margin-bottom: 10px;margin-top: 10px;padding-left: 12.25px;padding-right: 13.25px;border-radius: 49px;margin-right: 12px;width: 197.8125px;height: 36.25px;padding-top: 4.625px;" href="https://brbamiignuy.typeform.com/to/xceYAALX">Partnership Request</a>
                            <p class="text-left font-weight-light mb-0" style="padding-right: 0px;padding-left: 15px;padding-bottom: 214px;color: rgb(0,0,0);height: 97px;margin-top: 7px;margin-bottom: 0px;">If you are interested in partnering with TUM.ai (<strong>Makeathon-challenge setter, Industry project partner, workshops, projects, events</strong>, etc. please use the "Partnership Request" typeform.<br><br>For any other <strong>general request</strong>&nbsp;please reach out to us via&nbsp;<strong>contact@tum-ai.com</strong><br><br><a href="impressum" style="font-size: 16px;color: #212121;padding: 0px;padding-left: 0px;text-align: left;margin-left: 25px;margin-bottom: 0px;"><strong>Terms &amp; Conditions</strong></a><br></p>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
    <div class="article-clean">
        <div class="container">
            <div class="row">
                <div class="col-lg-10 col-xl-8 offset-lg-1 offset-xl-2">
                    <div class="intro">
                        <h1 class="text-center" style="font-family: Lato, sans-serif;color: rgb(0,0,0);font-size: 32px;"><strong>Convolutional</strong><br><strong>Neural Networks in keras</strong><br></h1>
                        <p class="text-center"><span class="by" style="font-family: Lato, sans-serif;font-size: 12px;">by</span> <a href="https://www.linkedin.com/in/jakob-kruse-b7293a197/" style="font-family: Lato, sans-serif;font-size: 12px;">jakOb Kruse</a><span class="date" style="font-family: Lato, sans-serif;font-size: 12px;">APRIL 21ST, 2020</span></p><img class="img-fluid" src="assets/img/blog/blog-cnn/desk.jpg" style="border-radius: 10px;">
                    </div>
                    <div class="text">
                        <p style="font-family: Lato, sans-serif;font-size: 16px;color: rgb(0,0,0);text-align: justify;">Convolutional neural networks are a class of deep neural networks which are usually used for image analysis. They usually consist of convolutional, pooling and fully connected layers, which will all be explained in this article. The layers are usually fully connected, which tends to lead to overfitting in larger networks. Therefore, additional regularization and normalization layers are often used to avoid this problem. <br><br>This article will explain the functionality of the different layers in convolutional neural networks and show a simple CNN implementation in the commonly used Python machine learning framework keras. <br></p>
                        <p></p>
                        <h2 style="font-family: Lato, sans-serif;font-size: 20px;color: #000000;">1. Motivation</h2>
                        <p style="font-family: Lato, sans-serif;color: rgb(0,0,0);font-size: 16px;text-align: justify;">A question that you might ask yourself is why we are using these special convolutional neural networks at all. Why not just use a normal neural network for the task of image classification?<br><br>There are several reasons for that. One very important reason is that images tend to be relatively large, which leads to a lot of parameters in standard neural networks. As an example, let's use a 256x256 pixel color image. This image has 256*256 = 65536 pixels with 3 RGB color channels, which leads to ~196.000 input parameters. If we use a first hidden layer with 1024 neurons, we have more than 200 million parameters only in our first layer. Updating these parameters with backpropagation involves a huge amount of computations. Using convolutional neural networks bypasses this problem by using the concept of filters. <br><br>Apart from that, convolutional neural networks are more capable of detecting patterns in spatial areas of an image and can find patterns anywhere in the image. As an example, if we train a standard neural network with a certain cat image and then feed a shifted version of this picture, the neural network will probably not detect the cat because other neurons will be activated. Using the concept of filters, this can be avoided in convolutional neural networks.<br></p>
                        <h2 style="font-family: Lato, sans-serif;color: #000000;font-size: 20px;">2. keras Introduction</h2>
                        <p style="font-family: Lato, sans-serif;font-size: 16px;color: rgb(0,0,0);text-align: justify;">keras is a Python deep learning framework which is very user-friendly but also powerful. <br>Let us install keras and some other packages we need:<br></p><script src="https://cdn.jsdelivr.net/gh/google/code-prettify@master/loader/run_prettify.js"></script>
<pre class="prettyprint">
  <code class="prettyprint">
    $ pip3 install keras tensorflow numpy mnist
  </code>
</pre>
                        <p style="font-family: Lato, sans-serif;font-size: 16px;color: rgb(0,0,0);">Then, import the required packages into your program:<br></p><script src="https://cdn.jsdelivr.net/gh/google/code-prettify@master/loader/run_prettify.js"></script>
<pre class="prettyprint">
  <code class="prettyprint">
    import numpy as np
    import keras
  </code>
</pre>
                        <p style="font-family: Lato, sans-serif;font-size: 16px;color: rgb(0,0,0);text-align: justify;">I will use the MNIST dataset in this article. The mnist dataset consists of 60000 images of handwritten digits (0 - 9) and is a commonly used beginner dataset. The goal is to classify the digits in the images. Each image is 28x28 pixels large and has only one gray-scale channel. First, let's load the mnist dataset:<br></p><script src="https://cdn.jsdelivr.net/gh/google/code-prettify@master/loader/run_prettify.js"></script>
<pre class="prettyprint">
  <code class="prettyprint">
    from keras.datasets import mnist
    (train_images, train_labels), (test_images, test_labels) = mnist.load_data()
  </code>
</pre>
                        <figure><img class="figure-img" src="assets/img/blog/blog-cnn/example_images.png">
                            <figcaption style="font-family: Lato, sans-serif;">Example images from the mnist dataset</figcaption>
                        </figure>
                        <p style="font-family: Lato, sans-serif;font-size: 16px;color: rgb(0,0,0);text-align: justify;">Now, the dataset should be preprocessed to be easily used by the keras package. We therefore convert the labels of the image to categorical labels. This converts our single label into a 10-element label vector which contains only zeros and a single one (representing the digit) for each image.<br></p><script src="https://cdn.jsdelivr.net/gh/google/code-prettify@master/loader/run_prettify.js"></script>
<pre class="prettyprint">
  <code class="prettyprint">
    from keras.utils import to_categorical
    train_images = np.expand_dims(train_images, axis=3)
    test_images = np.expand_dims(test_images, axis=3)
    train_labels = to_categorical(train_labels)
    test_labels = to_categorical(test_labels)
    print(train_images.shape)    # (60000, 28, 28, 1)
    print(train_labels.shape)    # (60000, 10)

  </code>
</pre>
                        <p style="font-family: Lato, sans-serif;font-size: 16px;color: rgb(0,0,0);text-align: justify;">Let's start building the convolutional neural network. We first create a Sequential model in keras. Later, we then add the different types of layers to this model.<br></p><script src="https://cdn.jsdelivr.net/gh/google/code-prettify@master/loader/run_prettify.js"></script>
<pre class="prettyprint">
  <code class="prettyprint">
    from keras.models import Sequential
    model = Sequential()
  </code>
</pre>
                        <h2 style="font-family: Lato, sans-serif;font-size: 20px;color: #000000;">3. Layers</h2>
                        <h2 style="font-family: Lato, sans-serif;font-size: 20px;color: #000000;">3.1 Dense and Flatten</h2>
                        <p style="font-family: Lato, sans-serif;font-size: 16px;color: rgb(0,0,0);text-align: justify;">First, let us create a simple standard neural network in keras as a baseline. We start by flattening the image through the use of a Flatten layer. Then, we will use two fully connected layers with 32 neurons and ‘relu’ activation function as hidden layers and one fully connected softmax layer with ten neurons as our output layer.<br></p><script src="https://cdn.jsdelivr.net/gh/google/code-prettify@master/loader/run_prettify.js"></script>
<pre class="prettyprint">
  <code class="prettyprint">
    from keras.layers import Flatten, Dense
    model.add(Flatten(input_shape=(28, 28, 1)))
    model.add(Dense(32, activation='relu'))
    model.add(Dense(32, activation='relu'))
    model.add(Dense(10, activation='softmax'))
  </code>
</pre>
                        <p style="font-family: Lato, sans-serif;font-size: 16px;color: rgb(0,0,0);">Let us verify that everything worked as expected by viewing the model summary.<br></p><script src="https://cdn.jsdelivr.net/gh/google/code-prettify@master/loader/run_prettify.js"></script>
<pre class="prettyprint">
  <code class="prettyprint">
    model.summary()

OUT:
Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
flatten_1 (Flatten)          (None, 784)               0         
_________________________________________________________________
dense_1 (Dense)              (None, 32)                25120     
_________________________________________________________________
dense_2 (Dense)              (None, 32)                1056      
_________________________________________________________________
dense_3 (Dense)              (None, 10)                330       
=================================================================
Total params: 26,506
Trainable params: 26,506
Non-trainable params: 0
_________________________________________________________________
  </code>
</pre>
                        <p style="font-family: Lato, sans-serif;font-size: 16px;color: rgb(0,0,0);text-align: justify;">To evaluate the performance of this baseline network, we need to set the loss function and choose the optimizer we want to use. Since we have categorical labels in our classification task, we will use the categorical crossentropy loss. As an optimizer, we will use the commonly used Adam optimizer. Then, we train (fit) the network with batch size 128 and 10 epochs.<br></p><script src="https://cdn.jsdelivr.net/gh/google/code-prettify@master/loader/run_prettify.js"></script>
<pre class="prettyprint">
  <code class="prettyprint">
    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
    model.fit(train_images, train_labels,
          batch_size=128,
          epochs=10,
          validation_data=(test_images, test_labels))
          
OUT:
.....
Epoch 10/10
60000/60000 [==============================] - 2s 26us/step 
- loss: 0.2728 - accuracy: 0.9237 - val_loss: 0.3089 - val_accuracy: 0.9233
  </code>
</pre>
                        <p style="font-family: Lato, sans-serif;font-size: 16px;color: rgb(0,0,0);text-align: justify;">As we can see, the baseline model already achieves a pretty good test accuracy of 92.33% for this task. However, let us see if we can improve these results by using a convolutional neural network.<br></p>
                        <h2 style="font-family: Lato, sans-serif;font-size: 20px;color: #000000;">3.2 Convolutional Layer</h2>
                        <p style="font-family: Lato, sans-serif;font-size: 16px;color: rgb(0,0,0);text-align: justify;">Convolutional neural networks are networks that use convolutional layers. These layers are the main reason why CNNs outperform NNs when it comes to image classification. Let us look at how these convolutional layers work.<br><br>Convolutional layers consist of a set of filters, which are used to look at spatial areas of the image. For example, if we use a 28 x 28 x 3 image, we could use a 5 x 5 x 3 filter, which looks at a 5x5 pixel area of the image. The last dimension of the filter is always equal to the last input dimension (the number of channels of the image).<br></p>
                        <figure><img class="figure-img" src="assets/img/blog/blog-cnn/completefilter.png">
                            <figcaption>Convolutional layer visualization</figcaption>
                        </figure>
                        <p style="font-family: Lato, sans-serif;font-size: 16px;color: rgb(0,0,0);text-align: justify;">The output of the convolutional layer is calculated by performing an element-wise multiplication<br>of the filter with the area of the image that the filter currently looks at. Then, the results of the multiplications are summed up to create one of the outputs. Finally, the filter is moved one pixel (or multiple pixels, see later) to the right and the next output is calculated. This is done for all rows and columns so that the output is a 2D matrix.&nbsp;<br>(Output dimension for the example above: (28-5+1) x (28-5+1) = 24 x 24).<br></p>
                        <figure><img class="figure-img" src="assets/img/blog/blog-cnn/Untitled%20Diagram(1).png">
                            <figcaption>The spatial areas that the filter looks at for the first row of the output image (stride 1)</figcaption>
                        </figure>
                        <p style="font-family: Lato, sans-serif;font-size: 16px;color: rgb(0,0,0);text-align: justify;">Normally, multiple filters are used in a convolutional layer, resulting in a 3-dimensional output of dimensions (outputDIM1 x outputDIM2 x numFilters).<br><br><strong><span style="text-decoration: underline;">Padding:</span> </strong>When using a filter with a size of 2x2 or larger, the output dimension of the convolutional layer will always be smaller than the input dimension. To avoid that, we can use a technique called padding. This means that we add zeros around the input of the convolutional layer to get an output that is larger. For example, if we use a 28x28 image with filter size 3 and a padding of 1 (this adds layer of zeros around the image), the output of the convolutional layer will also be of dimension 28x28.<br>Note: In keras, we can specify padding=”same” to automatically add padding such that the output and input dimensions are the same.<br></p>
                        <figure><img class="figure-img" src="assets/img/blog/blog-cnn/Untitled%20Diagram(2).png">
                            <figcaption>Padding of 1</figcaption>
                        </figure>
                        <p style="font-family: Lato, sans-serif;font-size: 16px;color: rgb(0,0,0);text-align: justify;"><strong><span style="text-decoration: underline;">Stride:</span></strong> The stride specifies the number of pixels that the filter is moved between the spatial areas that it looks at. If we use a stride of 2, the filter is moved two pixels to the right to produce the next output.<br><br><strong><span style="text-decoration: underline;">keras:</span></strong><br>Now, let us create a simple convolutional neural network in keras and see how it performs. First, I will add two convolutional layers to our current neural network. The first layer uses 64 filters of size 3x3, the second one uses 32 filters of the same size.<br></p><script src="https://cdn.jsdelivr.net/gh/google/code-prettify@master/loader/run_prettify.js"></script>
<pre class="prettyprint">
  <code class="prettyprint">
    from keras.layers import Dense, Conv2D, Flatten
    model = Sequential()
    model.add(Conv2D(64, (3, 3), strides=(1, 1), padding='same', activation='relu', input_shape=(28, 28, 1)))
    model.add(Conv2D(32, (3, 3), strides=(1, 1), padding='same', activation='relu'))
    model.add(Flatten())
    model.add(Dense(32, activation='relu'))
    model.add(Dense(32, activation='relu'))
    model.add(Dense(10, activation='softmax'))
  </code>
</pre>
                        <p style="font-family: Lato, sans-serif;font-size: 16px;color: rgb(0,0,0);text-align: justify;">When looking at the summary, we can see that the convolutional layers have very few parameters compared to the fully connected layers in the network. The large number of parameters in the fully connected layers can result in a longer training time and larger memory footprint. Let us train the network and see the results.</p><script src="https://cdn.jsdelivr.net/gh/google/code-prettify@master/loader/run_prettify.js"></script>
<pre class="prettyprint">
  <code class="prettyprint">
    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
    model.fit(train_images, train_labels,
          batch_size=128,
          epochs=10,
          validation_data=(test_images, test_labels))
OUT:
.....
Epoch 10/10
60000/60000 [==============================] - 188s 3ms/step 
- loss: 0.0137 - accuracy: 0.9956 - val_loss: 0.1022 - val_accuracy: 0.9795
  </code>
</pre>
                        <p style="font-family: Lato, sans-serif;font-size: 16px;color: rgb(0,0,0);text-align: justify;">The network now achieves an accuracy of 97.95%, which is a solid result. However, the training time has increased a lot. Lets see if we can reduce it throughout the rest of this article.</p>
                        <h2 style="font-family: Lato, sans-serif;font-size: 20px;color: #000000;">3.2 Pooling Layer</h2>
                        <p style="font-family: Lato, sans-serif;font-size: 16px;color: rgb(0,0,0);text-align: justify;">The pooling layer is another neural network layer that is often used in CNNs. Its concept is very simple. Neighbor pixels in images often have similar values and therefore, neighboring outputs of a convolutional layer often contain redundant information. Pooling layers address this problem by removing some of this redundancy.<br><br>Pooling layers look at an area of the convolutional output and perform a simple operation on it. Examples for these operations are max, min and average. For example, a max-pooling layer chooses the maximum value from all its input values as output. The area that the pooling layer looks at is defined by the pool size. A pool size of 2 means that the pooling operations look at a 2x2 area and the output dimensions are both halfed. For example, applying such a pooling layer to a 24x24 output of a convolutional layer results in a 12x12 pooling layer output. The number of channels remains untouched by the pooling layer.<br></p>
                        <figure><img class="figure-img" src="assets/img/blog/blog-cnn/pooling.png">
                            <figcaption>Max Pooling Layer with pool size 2</figcaption>
                        </figure>
                        <p style="font-family: Lato, sans-serif;font-size: 16px;color: rgb(0,0,0);">Let's add pooling layers to our neural network and see the results.</p><script src="https://cdn.jsdelivr.net/gh/google/code-prettify@master/loader/run_prettify.js"></script>
<pre class="prettyprint">
  <code class="prettyprint">
    from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D
    model = Sequential()
    model.add(Conv2D(64, (3, 3), strides=(1, 1), padding='same', activation='relu', input_shape=(28, 28, 1)))
    model.add(MaxPooling2D(pool_size=(2, 2)))
    model.add(Conv2D(32, (3, 3), strides=(1, 1), padding='same', activation='relu'))
    model.add(MaxPooling2D(pool_size=(2, 2)))
    model.add(Flatten())
    model.add(Dense(32, activation='relu'))
    model.add(Dense(32, activation='relu'))
    model.add(Dense(10, activation='softmax'))
    model.summary()
    
OUT:
Model: "sequential_3"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_3 (Conv2D)            (None, 28, 28, 64)        640       
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 14, 14, 64)        0         
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 14, 14, 32)        18464     
_________________________________________________________________
max_pooling2d_4 (MaxPooling2 (None, 7, 7, 32)          0         
_________________________________________________________________
flatten_3 (Flatten)          (None, 1568)              0         
_________________________________________________________________
dense_5 (Dense)              (None, 32)                50208     
_________________________________________________________________
dense_6 (Dense)              (None, 32)                1056      
_________________________________________________________________
dense_7 (Dense)              (None, 10)                330       
=================================================================
Total params: 70,698
Trainable params: 70,698
Non-trainable params: 0
_________________________________________________________________
  </code>
</pre>
                        <p style="font-family: Lato, sans-serif;font-size: 16px;color: rgb(0,0,0);text-align: justify;">The summary shows that we could reduce our number of trainable parameters by more than a factor of 10 compared to the previous case. When training the network using the same command that we used earlier, we can see that the time was reduced from 188s to 35s per episode while the accuracy increased to 98.38%.</p><script src="https://cdn.jsdelivr.net/gh/google/code-prettify@master/loader/run_prettify.js"></script>
<pre class="prettyprint">
  <code class="prettyprint">
OUT:
.....
Epoch 10/10
60000/60000 [==============================] - 35s 584us/step 
- loss: 0.0229 - accuracy: 0.9929 - val_loss: 0.0621 - val_accuracy: 0.9838
  </code>
</pre>
                        <h2 style="font-family: Lato, sans-serif;font-size: 20px;color: #000000;">4. Further improvements to the architecture</h2>
                        <p style="font-family: Lato, sans-serif;font-size: 16px;color: rgb(0,0,0);text-align: justify;">The architecture we created in this article is still fairly simple. In this part, I want to mention some options to further improve the network. I won't explain these techniques in detail here, if you need more information on them, a simple Google search will help.<br><br><strong>Regularization:</strong><br>The network we created does not seem to overfit the data. If overfitting occurs in your application/network, adding Dropout layers or other regularization techniques (L1, L2, L1 and L2, see keras documentation for details) can help reduce bias in the network.<br><br><strong>Batch Normalization:</strong><br>Adding BatchNormalization layers can help speed up the training of the neural network.<br><br><strong>Removing Fully Connected Layers:</strong><br>Removing the fully connected layers at the end of the network can decrease the computational complexity. In the network from this article, removing the two hidden fully connected layers results in a small reduction of training time while having a comparable accuracy.<br><br><strong>Inception Modules:</strong><br>The inception module was invented by Google and basically is a small network inside the network. It combines multiple parallel convolutional and pooling layers that work well on image classification tasks. The inception module with dimensionality reduction should be used rather than its naive version.<br><br><strong>Residual connections:</strong><br>In very deep networks, adding residual connections between the layers can help the network perform better.</p>
                        <h2 style="font-family: Lato, sans-serif;font-size: 20px;color: #000000;">5. Conclusion</h2>
                        <p style="font-family: Lato, sans-serif;font-size: 16px;color: rgb(0,0,0);text-align: justify;margin-bottom: 54px;">In this article, we looked at the concept of convolutional neural networks. We first took a closer look at convolutional layers and pooling layers, which are the most important layers in CNNs.<br>To get some practical experience, we looked at an example implementation of a CNN in keras which already achieved an accuracy of more than 98% on the mnist training set after only 10 epochs.<br>I hope that you have learned that CNNs are very powerful tools for image classification tasks and that the article helps you to implement your very own CNN.<br><br>Cheers, <br>Jakob.</p>
                    </div>
                </div>
            </div>
        </div>
    </div>
    <div class="footer-basic" style="margin-top: 53px;padding: 0px;background: linear-gradient(-174deg, rgb(11,11,11) 21%, #1e0845 100%), rgb(11,11,11);padding-bottom: 124px;height: 1%;">
        <div style="height: 13px;background: linear-gradient(2deg, var(--indigo), #45b69c), var(--red);margin: -31px;margin-right: 0px;margin-left: 0px;margin-top: -1px;"></div>
        <footer>
            <div class="container mt-md-5">
                <div class="row justify-content-center" data-aos="fade" style="margin-top: 69px;margin-bottom: -58px;text-align: center;">
                    <div class="col-md-4 mb-3" style="text-align: center;"><div class="text-center"><a class="no-underline" href="https://instagram.com/tum.ai_official?igshid=104nv2t3krc04"> 
    <div class="d-flex justify-content-center align-items-center"><img class="instagramImage" style="width:40px; margin:2px; border-radius:10px;" src="assets/img/other/Instagram_logo.png" /></div>
    <h4 class="font-lato" style="color:white;font-size:20px;">Follow us on Instagram</h4>
    <h5 class="font-lato" style="color:#909090;font-size:16px;">We frequently post the newest insights!</h5></a>
</div></div>
                    <div class="col-md-4 mb-3" style="text-align: center;"><div class="text-center"><a class="no-underline" href="https://de.linkedin.com/company/tum-ai"> 
    <span class="fab fa-linkedin fa-3x icon" style="color:white" aria-hidden="true"></span>
    <h4 class="font-lato" style="color:white;font-size:20px;">Let's connect on LinkedIn</h4>
    <h5 class="font-lato" style="color:#909090;font-size:16px;">Engage with our great community !</h5></a>
    </div></div>
                </div>
            </div>
            <ul class="list-inline" style="margin-bottom: 8px;margin-top: 47px;padding-top: 11px;">
                <li class="list-inline-item" style="margin-right: 0px;padding-right: 5px;padding-left: 5px;"><a href="#" data-toggle="modal" data-target="#modal1" style="font-family: Lato, sans-serif;font-size: 17px;color: rgb(255,255,255);text-decoration: underline;">Contact</a></li>
                <li class="list-inline-item" style="margin-right: 0px;padding-right: 5px;padding-left: 5px;"><a href="impressum" style="font-family: Lato, sans-serif;font-size: 15px;color: rgb(255,255,255);text-decoration: underline;">Imprint</a></li>
                <li class="list-inline-item" style="text-decoration: underline;padding-right: 0px;padding-left: 5px;"><a href="datenschutz" style="font-family: Lato, sans-serif;font-size: 16px;color: rgb(255,255,255);">Terms&amp;Security</a></li>
                <li class="list-inline-item" style="text-decoration: underline;padding-right: 5px;padding-left: 0px;"><a href="https://www.linkedin.com/in/stefanrmmr/" style="font-family: Lato, sans-serif;font-size: 16px;color: rgb(255,255,255);">Website Admin</a></li>
            </ul>
        </footer>
        <p class="copyright" style="font-family: Lato, sans-serif;margin-top: 3px;border-color: rgb(255,255,255);font-weight: bold;color: rgb(255,255,255);margin-bottom: -94px;">TUM.ai © 2022 - Website by IT &amp; Infrastructure department</p>
    </div>
    <script src="assets/js/jquery.min.js"></script>
    <script src="assets/bootstrap/js/bootstrap.min.js"></script>
    <script src="assets/js/bs-init.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/aos/2.3.4/aos.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/emailjs-com@2/dist/email.min.js"></script>
    <script src="assets/js/overlay.js"></script>
    <script src="assets/js/accordeon.js"></script>
    <script src="assets/js/flipCart.js"></script>
    <script src="https://kit.fontawesome.com/c6b49bff09.js"></script>
    <script src="assets/js/video.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r121/three.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/vanta@latest/dist/vanta.net.min.js"></script>
    <script src="assets/js/Bold-BS4-Jumbotron-with-Particles-js.js"></script>
    <script src="assets/js/caroussel_linkedin.js"></script>
    <script src="https://pretix.eu/widget/v1.en.js"></script>
    <script src="assets/js/Popup-Modal-with-Cookie-1.js"></script>
    <script src="assets/js/Popup-Modal-with-Cookie.js"></script>
    <script src="assets/js/responsive-blog-card-slider-1.js"></script>
    <script src="assets/js/responsive-blog-card-slider.js"></script>
    <script src="assets/js/teamShower.js"></script>
</body>

</html>